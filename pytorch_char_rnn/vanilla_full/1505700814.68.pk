(dp0
S'train_loss'
p1
(lp2
F4.654541015625
aF4.590369567871094
aF4.529988098144531
aF4.467556762695312
aF4.401275024414063
aF4.321368103027344
aF4.22713134765625
aF4.123527221679687
aF4.012623291015625
aF3.9066351318359374
aF3.783885498046875
aF3.6970977783203125
aF3.6351199340820313
aF3.564700012207031
aF3.511091613769531
aF3.4767987060546877
aF3.4136822509765623
aF3.413210144042969
aF3.361170349121094
aF3.355335388183594
aF3.345417785644531
aF3.32817138671875
aF3.282669677734375
aF3.2488162231445314
aF3.2816748046875
aF3.22078857421875
aF3.21670166015625
aF3.18929931640625
aF3.175252685546875
aF3.1783074951171875
aF3.149012145996094
aF3.103800964355469
aF3.083919677734375
aF3.0934957885742187
aF3.0448788452148436
aF3.04712890625
aF3.040391845703125
aF3.0096630859375
aF3.00833740234375
aF2.9923696899414063
aF2.961684265136719
aF2.937898864746094
aF2.9513128662109374
aF2.9304278564453123
aF2.9037442016601562
aF2.903117370605469
aF2.8813238525390625
aF2.8623504638671875
aF2.8335369873046874
aF2.85468994140625
aF2.8245309448242186
aF2.8194143676757815
aF2.7989981079101565
aF2.7897610473632812
aF2.7888827514648438
aF2.768193359375
aF2.7581207275390627
aF2.737406005859375
aF2.7282595825195313
aF2.7271197509765623
aF2.704013671875
aF2.7075381469726563
aF2.6562869262695314
aF2.679659423828125
aF2.6609542846679686
aF2.647918701171875
aF2.6469351196289064
aF2.6339373779296875
aF2.6311605834960936
aF2.59414794921875
aF2.6142938232421873
aF2.60883056640625
aF2.5906622314453127
aF2.582060546875
aF2.553076171875
aF2.5753033447265623
aF2.5495945739746095
aF2.543484344482422
aF2.551531982421875
aF2.5532379150390625
aF2.5459454345703123
aF2.5503758239746093
aF2.513288116455078
aF2.515605163574219
aF2.5127029418945312
aF2.490254669189453
aF2.4815138244628905
aF2.485919952392578
aF2.4958979797363283
aF2.4697279357910156
aF2.4679725646972654
aF2.462364044189453
aF2.4665174865722657
aF2.4727548217773436
aF2.4466156005859374
aF2.4642909240722655
aF2.4385186767578126
aF2.4455032348632812
aF2.430020446777344
aF2.4048155212402342
asS'test_loss'
p3
(lp4
F4.5921142578125
aF4.528186645507812
aF4.466908569335938
aF4.392152709960937
aF4.3155825805664065
aF4.226824340820312
aF4.126868591308594
aF4.012753601074219
aF3.9000894165039064
aF3.8021731567382813
aF3.69049560546875
aF3.632471008300781
aF3.5596728515625
aF3.5040328979492186
aF3.4601031494140626
aF3.4362335205078125
aF3.395269470214844
aF3.39281494140625
aF3.3620315551757813
aF3.3453988647460937
aF3.310679626464844
aF3.3009234619140626
aF3.276168212890625
aF3.2304864501953126
aF3.22387451171875
aF3.2137884521484374
aF3.201416015625
aF3.1740817260742187
aF3.131117858886719
aF3.1169927978515624
aF3.11619384765625
aF3.0733462524414064
aF3.0725588989257813
aF3.066407470703125
aF3.054095458984375
aF3.031724853515625
aF3.002174072265625
aF3.0077548217773438
aF2.9506512451171876
aF2.9746823120117187
aF2.9634454345703123
aF2.9601239013671874
aF2.952544860839844
aF2.9046499633789065
aF2.9068753051757814
aF2.8990325927734375
aF2.8400494384765627
aF2.8589248657226562
aF2.8336871337890623
aF2.824376220703125
aF2.8349765014648436
aF2.7952780151367187
aF2.787418212890625
aF2.7769952392578126
aF2.768296813964844
aF2.7451608276367185
aF2.730219421386719
aF2.7210488891601563
aF2.7111163330078125
aF2.702881164550781
aF2.6936221313476563
aF2.674549560546875
aF2.67353515625
aF2.655104064941406
aF2.6607452392578126
aF2.6549258422851563
aF2.6191256713867186
aF2.6132891845703123
aF2.5916595458984375
aF2.6105136108398437
aF2.590687255859375
aF2.579622497558594
aF2.5790521240234376
aF2.556124725341797
aF2.561772766113281
aF2.5627777099609377
aF2.5475894165039064
aF2.5505064392089842
aF2.529571533203125
aF2.5364195251464845
aF2.497808380126953
aF2.5078549194335937
aF2.506975555419922
aF2.5179922485351565
aF2.4820492553710936
aF2.4781562805175783
aF2.473993225097656
aF2.4746861267089844
aF2.4762828063964846
aF2.466694793701172
aF2.449085540771484
aF2.4492478942871094
aF2.435962982177734
aF2.4443145751953126
aF2.4454661560058595
aF2.433000030517578
aF2.4327078247070313
aF2.4258078002929686
aF2.422354278564453
aF2.4034117126464842
asS'chunk_len'
p5
I200
sS'learning_rate'
p6
F0.0008906490320425426
sS'batch_size'
p7
I100
sS'n_epochs'
p8
I100
sS'elapsed_time'
p9
S'1m 18s'
p10
sS'final_test_loss'
p11
F2.4034117126464842
sS'num_layers'
p12
cnumpy.core.multiarray
scalar
p13
(cnumpy
dtype
p14
(S'i8'
p15
I0
I1
tp16
Rp17
(I3
S'<'
p18
NNNI-1
I-1
I0
tp19
bS'\x02\x00\x00\x00\x00\x00\x00\x00'
p20
tp21
Rp22
sS'model'
p23
S'vanilla_tanh'
p24
sS'hidden_size'
p25
g13
(g17
S'f\x00\x00\x00\x00\x00\x00\x00'
p26
tp27
Rp28
s.