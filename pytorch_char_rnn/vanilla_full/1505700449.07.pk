(dp0
S'train_loss'
p1
(lp2
F4.664519653320313
aF4.63710205078125
aF4.610281066894531
aF4.581572570800781
aF4.551692810058594
aF4.5311669921875
aF4.493302001953125
aF4.470412902832031
aF4.435711364746094
aF4.407715454101562
aF4.3785794067382815
aF4.343512268066406
aF4.3098974609375
aF4.282525939941406
aF4.244367065429688
aF4.210042419433594
aF4.171382446289062
aF4.126283874511719
aF4.083349914550781
aF4.0345462036132815
aF3.9888519287109374
aF3.9376177978515625
aF3.8867782592773437
aF3.8354067993164063
aF3.7716162109375
aF3.71278564453125
aF3.667850341796875
aF3.6191827392578126
aF3.5626766967773436
aF3.502347717285156
aF3.4749874877929687
aF3.4468756103515625
aF3.4166168212890624
aF3.3836346435546876
aF3.366641845703125
aF3.3178692626953126
aF3.313265075683594
aF3.2844619750976562
aF3.2635894775390626
aF3.2480401611328125
aF3.245654296875
aF3.258790283203125
aF3.2131024169921876
aF3.2184353637695313
aF3.1876763916015625
aF3.1842855834960937
aF3.188380126953125
aF3.1429144287109376
aF3.149451904296875
aF3.146807861328125
aF3.124556579589844
aF3.1147296142578127
aF3.1055258178710936
aF3.0819021606445314
aF3.0606314086914064
aF3.0751211547851565
aF3.0658624267578123
aF3.073572082519531
aF3.0570028686523436
aF3.0150997924804686
aF3.0230142211914064
aF3.0103387451171875
aF3.0045892333984376
aF3.000832214355469
aF2.98693359375
aF2.966896667480469
aF2.969031982421875
aF2.954145812988281
aF2.948092346191406
aF2.957459716796875
aF2.960582275390625
aF2.9569610595703124
aF2.9030642700195313
aF2.9187161254882814
aF2.932628479003906
aF2.918570251464844
aF2.8946630859375
aF2.8852508544921873
aF2.869331970214844
aF2.881728210449219
aF2.886205749511719
aF2.8806771850585937
aF2.8718020629882814
aF2.8633737182617187
aF2.834952697753906
aF2.8411264038085937
aF2.8664306640625
aF2.8272195434570313
aF2.8306649780273436
aF2.808443603515625
aF2.815009765625
aF2.8153109741210938
aF2.828285827636719
aF2.812641296386719
aF2.787891845703125
aF2.7999478149414063
aF2.793926086425781
aF2.78138671875
aF2.7733865356445313
aF2.759330139160156
asS'test_loss'
p3
(lp4
F4.640392761230469
aF4.612416687011719
aF4.582623291015625
aF4.557261657714844
aF4.526910400390625
aF4.498637084960937
aF4.467000427246094
aF4.439976501464844
aF4.410267944335938
aF4.379555358886718
aF4.33497314453125
aF4.310189208984375
aF4.282315673828125
aF4.244132995605469
aF4.206452331542969
aF4.160933837890625
aF4.12721923828125
aF4.082778015136719
aF4.033380737304688
aF3.992892150878906
aF3.944122619628906
aF3.892958984375
aF3.8276171875
aF3.7840777587890626
aF3.7231854248046874
aF3.6525054931640626
aF3.6001129150390625
aF3.556047058105469
aF3.522882995605469
aF3.475386962890625
aF3.455926818847656
aF3.39755859375
aF3.3926205444335937
aF3.3662960815429686
aF3.351087951660156
aF3.293660888671875
aF3.330446472167969
aF3.284169006347656
aF3.2753469848632815
aF3.25078125
aF3.2210565185546876
aF3.224736328125
aF3.2257830810546877
aF3.197064208984375
aF3.1748089599609375
aF3.1715155029296875
aF3.1546087646484375
aF3.145094909667969
aF3.1166592407226563
aF3.090416259765625
aF3.117872619628906
aF3.1069036865234376
aF3.0991741943359377
aF3.075111083984375
aF3.0529620361328127
aF3.034831848144531
aF3.051640625
aF3.0294418334960938
aF3.0343109130859376
aF3.0457058715820313
aF3.0071749877929688
aF2.997680358886719
aF2.99124755859375
aF2.9883880615234375
aF2.978057556152344
aF2.961659240722656
aF2.955968933105469
aF2.9566311645507812
aF2.9345526123046874
aF2.944761962890625
aF2.934209899902344
aF2.91779541015625
aF2.9038906860351563
aF2.889825439453125
aF2.918079833984375
aF2.929291076660156
aF2.8942941284179686
aF2.902510070800781
aF2.87694091796875
aF2.8770962524414063
aF2.875013732910156
aF2.865708923339844
aF2.8744320678710937
aF2.8712158203125
aF2.8543960571289064
aF2.8495919799804685
aF2.8144964599609374
aF2.8213287353515626
aF2.815086669921875
aF2.7962847900390626
aF2.80676025390625
aF2.797593078613281
aF2.787262268066406
aF2.797135009765625
aF2.7778445434570314
aF2.7974002075195314
aF2.7948095703125
aF2.7642727661132813
aF2.779421081542969
aF2.749836120605469
asS'chunk_len'
p5
I200
sS'learning_rate'
p6
F0.0003379288310463581
sS'batch_size'
p7
I100
sS'n_epochs'
p8
I100
sS'elapsed_time'
p9
S'0m 55s'
p10
sS'final_test_loss'
p11
F2.749836120605469
sS'num_layers'
p12
cnumpy.core.multiarray
scalar
p13
(cnumpy
dtype
p14
(S'i8'
p15
I0
I1
tp16
Rp17
(I3
S'<'
p18
NNNI-1
I-1
I0
tp19
bS'\x01\x00\x00\x00\x00\x00\x00\x00'
p20
tp21
Rp22
sS'model'
p23
S'vanilla_tanh'
p24
sS'hidden_size'
p25
g13
(g17
S'\x84\x00\x00\x00\x00\x00\x00\x00'
p26
tp27
Rp28
s.