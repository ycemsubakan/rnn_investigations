(dp0
S'train_loss'
p1
(lp2
F4.642265319824219
aF4.418175964355469
aF4.2098681640625
aF4.011234436035156
aF3.830682678222656
aF3.6582574462890625
aF3.4835861206054686
aF3.3580307006835937
aF3.207755432128906
aF3.1021524047851563
aF3.025235595703125
aF2.94426513671875
aF2.858839111328125
aF2.8391323852539063
aF2.800604248046875
aF2.7893246459960936
aF2.7533584594726563
aF2.7438702392578125
aF2.736177978515625
aF2.679035339355469
aF2.665882873535156
aF2.666532287597656
aF2.6710379028320315
aF2.6404489135742186
aF2.6292279052734373
aF2.638691101074219
aF2.600823974609375
aF2.603055419921875
aF2.6075701904296875
aF2.6038241577148438
aF2.5671035766601564
aF2.593439636230469
aF2.550750427246094
aF2.564547119140625
aF2.5658660888671876
aF2.5494708251953124
aF2.5524285888671874
aF2.5334207153320314
aF2.5535211181640625
aF2.5377182006835937
aF2.51937255859375
aF2.523900451660156
aF2.5274668884277345
aF2.5284613037109374
aF2.5235255432128905
aF2.5273062133789064
aF2.500559997558594
aF2.4950407409667967
aF2.508525543212891
aF2.5016049194335936
aF2.4888050842285154
aF2.511610565185547
aF2.4870787048339844
aF2.483215789794922
aF2.4890170288085938
aF2.504505310058594
aF2.4814703369140627
aF2.4792242431640625
aF2.474734649658203
aF2.4726106262207033
aF2.498782043457031
aF2.4781739807128904
aF2.4681573486328126
aF2.4712429809570313
aF2.467203369140625
aF2.457686004638672
aF2.4649560546875
aF2.4684010314941407
aF2.4596009826660157
aF2.457013702392578
aF2.449417724609375
aF2.4433250427246094
aF2.4494705200195312
aF2.464345245361328
aF2.437854461669922
aF2.464483337402344
aF2.452012481689453
aF2.4478172302246093
aF2.4403399658203124
aF2.4377787780761717
aF2.4256575012207033
aF2.4185195922851563
aF2.446852264404297
aF2.4354893493652345
aF2.431856689453125
aF2.4222096252441405
aF2.429027862548828
aF2.4198878479003905
aF2.435962677001953
aF2.42852783203125
aF2.4149192810058593
aF2.423201599121094
aF2.4119503784179686
aF2.4151171875
aF2.398872833251953
aF2.4034326171875
aF2.395620880126953
aF2.411874542236328
aF2.407869415283203
aF2.380540771484375
asS'test_loss'
p3
(lp4
F4.4164501953125
aF4.209244079589844
aF4.0123599243164065
aF3.8380133056640626
aF3.630928649902344
aF3.5060153198242188
aF3.3148226928710938
aF3.202913513183594
aF3.0932211303710937
aF2.9645376586914063
aF2.9328387451171873
aF2.8829165649414064
aF2.806927490234375
aF2.7968255615234376
aF2.7733834838867186
aF2.751075439453125
aF2.72874267578125
aF2.691045837402344
aF2.714116516113281
aF2.6704556274414064
aF2.6844281005859374
aF2.6304461669921877
aF2.62473876953125
aF2.611580810546875
aF2.618192138671875
aF2.623076171875
aF2.5967532348632814
aF2.5804949951171876
aF2.560599670410156
aF2.5597267150878906
aF2.571986083984375
aF2.5470689392089843
aF2.5634393310546875
aF2.559510040283203
aF2.5443955993652345
aF2.539780731201172
aF2.5274336242675783
aF2.5407354736328127
aF2.51538818359375
aF2.537578125
aF2.524527740478516
aF2.527273712158203
aF2.5036474609375
aF2.501607208251953
aF2.5100033569335936
aF2.499326171875
aF2.4978878784179686
aF2.496109924316406
aF2.4968687438964845
aF2.489768524169922
aF2.4826637268066407
aF2.494942932128906
aF2.484396514892578
aF2.479453430175781
aF2.4762034606933594
aF2.4892970275878907
aF2.4746250915527344
aF2.455751953125
aF2.461963958740234
aF2.4753550720214843
aF2.4654193115234375
aF2.4680799865722656
aF2.456856231689453
aF2.461697540283203
aF2.4601315307617186
aF2.4617494201660155
aF2.4417059326171877
aF2.463972930908203
aF2.448656005859375
aF2.441001281738281
aF2.4494760131835935
aF2.4506903076171875
aF2.443898162841797
aF2.4590708923339846
aF2.449840393066406
aF2.4426393127441406
aF2.4313104248046873
aF2.4386610412597656
aF2.42346923828125
aF2.43206787109375
aF2.4138050842285157
aF2.42952392578125
aF2.4210716247558595
aF2.4241323852539063
aF2.421562042236328
aF2.42087890625
aF2.414947814941406
aF2.4068557739257814
aF2.3951234436035156
aF2.3973574829101563
aF2.3967521667480467
aF2.4132850646972654
aF2.3836756896972657
aF2.400197296142578
aF2.383871307373047
aF2.40352294921875
aF2.4161004638671875
aF2.407735137939453
aF2.404424285888672
aF2.399905548095703
asS'chunk_len'
p5
I200
sS'learning_rate'
p6
F0.002521105796943981
sS'batch_size'
p7
I100
sS'n_epochs'
p8
I100
sS'elapsed_time'
p9
S'0m 59s'
p10
sS'final_test_loss'
p11
F2.399905548095703
sS'num_layers'
p12
cnumpy.core.multiarray
scalar
p13
(cnumpy
dtype
p14
(S'i8'
p15
I0
I1
tp16
Rp17
(I3
S'<'
p18
NNNI-1
I-1
I0
tp19
bS'\x01\x00\x00\x00\x00\x00\x00\x00'
p20
tp21
Rp22
sS'model'
p23
S'vanilla_tanh_diag'
p24
sS'hidden_size'
p25
g13
(g17
S'\xa5\x00\x00\x00\x00\x00\x00\x00'
p26
tp27
Rp28
s.