(dp0
S'train_loss'
p1
(lp2
F4.626241149902344
aF4.6081005859375
aF4.593289489746094
aF4.575251770019531
aF4.55500244140625
aF4.53953369140625
aF4.515748596191406
aF4.505396728515625
aF4.477611389160156
aF4.459810485839844
aF4.443767700195313
aF4.4260107421875
aF4.409419860839844
aF4.3903286743164065
aF4.3766482543945315
aF4.349001770019531
aF4.331169738769531
aF4.323063659667969
aF4.300984191894531
aF4.28506591796875
aF4.267096252441406
aF4.253030700683594
aF4.223803405761719
aF4.207620849609375
aF4.189913940429688
aF4.180190124511719
aF4.157810668945313
aF4.140013732910156
aF4.116177978515625
aF4.093477783203125
aF4.070161437988281
aF4.0728451538085935
aF4.049151306152344
aF4.031682739257812
aF4.022019653320313
aF3.99660400390625
aF3.9759820556640624
aF3.9650149536132813
aF3.9370257568359377
aF3.918072509765625
aF3.8953341674804687
aF3.894749755859375
aF3.8807107543945314
aF3.860096740722656
aF3.833376159667969
aF3.807908630371094
aF3.803309326171875
aF3.7858514404296875
aF3.760791931152344
aF3.748398742675781
aF3.726994934082031
aF3.72452880859375
aF3.7040170288085936
aF3.6746942138671876
aF3.6634292602539062
aF3.65898681640625
aF3.6340386962890623
aF3.628290710449219
aF3.604429016113281
aF3.5836587524414063
aF3.565312805175781
aF3.530210266113281
aF3.538025207519531
aF3.515549621582031
aF3.485432434082031
aF3.4946746826171875
aF3.475039367675781
aF3.44198486328125
aF3.431651611328125
aF3.418699951171875
aF3.4139605712890626
aF3.377888488769531
aF3.3745672607421877
aF3.3608963012695314
aF3.3605392456054686
aF3.333207092285156
aF3.3343115234375
aF3.30479736328125
aF3.2991604614257812
aF3.284016418457031
aF3.2662384033203127
aF3.246197509765625
aF3.242703552246094
aF3.221832580566406
aF3.247347717285156
aF3.2222088623046874
aF3.207337646484375
aF3.1852239990234374
aF3.190088195800781
aF3.183619384765625
aF3.152822265625
aF3.147747802734375
aF3.1458010864257813
aF3.11973876953125
aF3.129100341796875
aF3.0920706176757813
aF3.1197998046875
aF3.0804214477539062
aF3.0619882202148436
aF3.0582489013671874
asS'test_loss'
p3
(lp4
F4.6117724609375
aF4.595158996582032
aF4.574122314453125
aF4.555514526367188
aF4.5377804565429685
aF4.517666015625
aF4.498808898925781
aF4.477649230957031
aF4.465459594726562
aF4.444244384765625
aF4.426396179199219
aF4.404297790527344
aF4.39258056640625
aF4.370238647460938
aF4.353985290527344
aF4.330863647460937
aF4.31496826171875
aF4.295374755859375
aF4.282238464355469
aF4.276051635742188
aF4.245021667480469
aF4.2279931640625
aF4.207399597167969
aF4.1881100463867185
aF4.182199096679687
aF4.162742309570312
aF4.1386416625976565
aF4.113536682128906
aF4.101748657226563
aF4.084056091308594
aF4.070316772460938
aF4.0509164428710935
aF4.0257501220703125
aF4.011304931640625
aF4.00521728515625
aF3.980280456542969
aF3.9557254028320314
aF3.9445263671875
aF3.922982482910156
aF3.9045989990234373
aF3.890399169921875
aF3.863409423828125
aF3.8504898071289064
aF3.8234991455078124
aF3.816609191894531
aF3.790180969238281
aF3.7841726684570314
aF3.764545593261719
aF3.746331787109375
aF3.7221875
aF3.703633117675781
aF3.6895108032226562
aF3.681577453613281
aF3.649969482421875
aF3.6405429077148437
aF3.6127740478515626
aF3.594947509765625
aF3.5802789306640626
aF3.5615438842773437
aF3.5525936889648437
aF3.535679931640625
aF3.5079165649414064
aF3.5220181274414064
aF3.4892620849609375
aF3.484091796875
aF3.4595465087890624
aF3.4400128173828124
aF3.4502328491210936
aF3.4015322875976564
aF3.402663269042969
aF3.3798406982421874
aF3.3960556030273437
aF3.3496334838867186
aF3.3561026000976564
aF3.339366455078125
aF3.3215521240234374
aF3.2808648681640626
aF3.292203369140625
aF3.278095703125
aF3.2673208618164065
aF3.24945556640625
aF3.229696960449219
aF3.2210537719726564
aF3.208926086425781
aF3.2223541259765627
aF3.19951416015625
aF3.173860778808594
aF3.1430038452148437
aF3.165513610839844
aF3.15381103515625
aF3.141718444824219
aF3.1231893920898437
aF3.104006652832031
aF3.11202880859375
aF3.1127664184570314
aF3.0982046508789063
aF3.0970831298828125
aF3.080361633300781
aF3.0501229858398435
aF3.057581481933594
asS'chunk_len'
p5
I200
sS'learning_rate'
p6
F0.00014766713808040871
sS'batch_size'
p7
I100
sS'n_epochs'
p8
I100
sS'elapsed_time'
p9
S'1m 7s'
p10
sS'final_test_loss'
p11
F3.057581481933594
sS'num_layers'
p12
cnumpy.core.multiarray
scalar
p13
(cnumpy
dtype
p14
(S'i8'
p15
I0
I1
tp16
Rp17
(I3
S'<'
p18
NNNI-1
I-1
I0
tp19
bS'\x01\x00\x00\x00\x00\x00\x00\x00'
p20
tp21
Rp22
sS'model'
p23
S'vanilla_tanh_diag'
p24
sS'hidden_size'
p25
g13
(g17
S'\xd9\x00\x00\x00\x00\x00\x00\x00'
p26
tp27
Rp28
s.