(dp0
S'train_loss'
p1
(lp2
F4.623079528808594
aF4.6199169921875
aF4.613766784667969
aF4.608976440429688
aF4.6024954223632815
aF4.598356018066406
aF4.5912713623046875
aF4.586512145996093
aF4.581636962890625
aF4.575621337890625
aF4.5711666870117185
aF4.56488037109375
aF4.561517333984375
aF4.5535986328125
aF4.54953125
aF4.5417306518554685
aF4.540757446289063
aF4.532096557617187
aF4.527735900878906
aF4.522546997070313
aF4.515427551269531
aF4.511423034667969
aF4.504980773925781
aF4.499563293457031
aF4.493890380859375
aF4.490140075683594
aF4.47958251953125
aF4.477122497558594
aF4.470408020019531
aF4.467494812011719
aF4.460027770996094
aF4.454906616210938
aF4.447970886230468
aF4.443026428222656
aF4.439675903320312
aF4.43192138671875
aF4.425800170898437
aF4.419199523925781
aF4.409386901855469
aF4.405910339355469
aF4.3984243774414065
aF4.390264587402344
aF4.386788940429687
aF4.378942260742187
aF4.37534423828125
aF4.369152221679688
aF4.357566833496094
aF4.35352783203125
aF4.347545471191406
aF4.3415374755859375
aF4.335274047851563
aF4.324654541015625
aF4.316647033691407
aF4.314994506835937
aF4.307144470214844
aF4.294798583984375
aF4.289069519042969
aF4.285624389648437
aF4.276339721679688
aF4.265122985839843
aF4.260494995117187
aF4.249632568359375
aF4.249926147460937
aF4.231546936035156
aF4.2323291015625
aF4.2151556396484375
aF4.217129821777344
aF4.208342895507813
aF4.199994201660156
aF4.186535949707031
aF4.175557861328125
aF4.170527038574218
aF4.162834777832031
aF4.1525967407226565
aF4.150960693359375
aF4.136572570800781
aF4.119488830566406
aF4.11470947265625
aF4.106265563964843
aF4.104014282226562
aF4.093303527832031
aF4.074856262207032
aF4.061962585449219
aF4.053079528808594
aF4.048943786621094
aF4.0458285522460935
aF4.032306213378906
aF4.023071899414062
aF4.00169921875
aF3.9926947021484374
aF3.9892218017578127
aF3.983040771484375
aF3.96837890625
aF3.95845458984375
aF3.94302001953125
aF3.93470703125
aF3.9216961669921875
aF3.911088562011719
aF3.905828552246094
aF3.878820495605469
asS'test_loss'
p3
(lp4
F4.619181823730469
aF4.613672790527343
aF4.609362487792969
aF4.604166564941406
aF4.596946716308594
aF4.59166748046875
aF4.586757507324219
aF4.581206665039063
aF4.576505432128906
aF4.568674011230469
aF4.5624911499023435
aF4.55847412109375
aF4.556151733398438
aF4.548648376464843
aF4.545166931152344
aF4.536638793945312
aF4.532107238769531
aF4.525318298339844
aF4.521692199707031
aF4.5179745483398435
aF4.507595825195312
aF4.503130798339844
aF4.497205200195313
aF4.495828552246094
aF4.488782958984375
aF4.478617553710937
aF4.475542907714844
aF4.472199401855469
aF4.465450439453125
aF4.45648681640625
aF4.452139282226563
aF4.4490444946289065
aF4.443164367675781
aF4.4356640625
aF4.4290283203125
aF4.424417114257812
aF4.417347717285156
aF4.4147122192382815
aF4.403868713378906
aF4.402157897949219
aF4.387532043457031
aF4.386745910644532
aF4.379227600097656
aF4.3698031616210935
aF4.36288330078125
aF4.357156677246094
aF4.350791320800782
aF4.348888854980469
aF4.339412231445312
aF4.337169799804688
aF4.326186828613281
aF4.318789367675781
aF4.311520690917969
aF4.304830017089844
aF4.293327331542969
aF4.283696899414062
aF4.283738403320313
aF4.279062194824219
aF4.265516967773437
aF4.257339782714844
aF4.246067504882813
aF4.238595581054687
aF4.2295654296875
aF4.230048522949219
aF4.226694946289062
aF4.210314636230469
aF4.197543029785156
aF4.197621459960938
aF4.186463317871094
aF4.1822817993164065
aF4.1657861328125
aF4.163484191894531
aF4.143280029296875
aF4.140177307128906
aF4.132861633300781
aF4.117007446289063
aF4.112883911132813
aF4.100841979980469
aF4.091106567382813
aF4.088495483398438
aF4.08147705078125
aF4.062046508789063
aF4.058787536621094
aF4.050163269042969
aF4.034479370117188
aF4.0248486328125
aF4.017276306152343
aF4.00560302734375
aF3.9941534423828124
aF3.989091491699219
aF3.982145080566406
aF3.968927917480469
aF3.955575256347656
aF3.950723876953125
aF3.932774963378906
aF3.9189141845703124
aF3.920518798828125
aF3.8899371337890627
aF3.8870391845703125
aF3.8689706420898435
asS'chunk_len'
p5
I200
sS'learning_rate'
p6
F0.00010027958019737865
sS'batch_size'
p7
I100
sS'n_epochs'
p8
I100
sS'elapsed_time'
p9
S'1m 15s'
p10
sS'final_test_loss'
p11
F3.8689706420898435
sS'num_layers'
p12
cnumpy.core.multiarray
scalar
p13
(cnumpy
dtype
p14
(S'i8'
p15
I0
I1
tp16
Rp17
(I3
S'<'
p18
NNNI-1
I-1
I0
tp19
bS'\x02\x00\x00\x00\x00\x00\x00\x00'
p20
tp21
Rp22
sS'model'
p23
S'vanilla_tanh_diag'
p24
sS'hidden_size'
p25
g13
(g17
S'q\x00\x00\x00\x00\x00\x00\x00'
p26
tp27
Rp28
s.