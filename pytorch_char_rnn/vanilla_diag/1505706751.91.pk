(dp0
S'train_loss'
p1
(lp2
F4.656139831542969
aF4.524906311035156
aF4.398959655761718
aF4.2737338256835935
aF4.1562588500976565
aF4.030291137695312
aF3.9216571044921875
aF3.804554138183594
aF3.6954022216796876
aF3.609410705566406
aF3.5276947021484375
aF3.4298846435546877
aF3.3469442749023437
aF3.25685546875
aF3.210452880859375
aF3.131282958984375
aF3.084354248046875
aF3.021856384277344
aF2.982957763671875
aF2.9262091064453126
aF2.909068908691406
aF2.8559674072265624
aF2.8622860717773437
aF2.799134521484375
aF2.7691180419921877
aF2.7643194580078125
aF2.7710247802734376
aF2.7339483642578126
aF2.7128500366210937
aF2.7118655395507814
aF2.7087832641601564
aF2.6799862670898436
aF2.6833200073242187
aF2.6816702270507813
aF2.6757452392578127
aF2.66134765625
aF2.6598635864257814
aF2.659787902832031
aF2.6306692504882814
aF2.6444476318359373
aF2.602314453125
aF2.6077923583984375
aF2.6240005493164062
aF2.6019927978515627
aF2.578410949707031
aF2.5966607666015626
aF2.5898724365234376
aF2.57336181640625
aF2.5894012451171875
aF2.57781005859375
aF2.576568298339844
aF2.558105010986328
aF2.576357421875
aF2.5714892578125
aF2.5647540283203125
aF2.553556365966797
aF2.536864013671875
aF2.5649481201171875
aF2.557639923095703
aF2.5455007934570313
aF2.5509159851074217
aF2.5298304748535156
aF2.532551727294922
aF2.5190711975097657
aF2.530552978515625
aF2.541897888183594
aF2.514598693847656
aF2.5315350341796874
aF2.523501281738281
aF2.5173681640625
aF2.5145223999023436
aF2.5180343627929687
aF2.531083679199219
aF2.5158026123046877
aF2.5055543518066408
aF2.519444580078125
aF2.493138732910156
aF2.5220822143554686
aF2.515707244873047
aF2.5084877014160156
aF2.520058288574219
aF2.498288879394531
aF2.4967056274414063
aF2.4995822143554687
aF2.501511535644531
aF2.4963011169433593
aF2.5035472106933594
aF2.493245849609375
aF2.487290802001953
aF2.497222900390625
aF2.4840679931640626
aF2.484834747314453
aF2.463981170654297
aF2.480477752685547
aF2.4780537414550783
aF2.4890060424804688
aF2.492961578369141
aF2.485057678222656
aF2.5009756469726563
aF2.4793328857421875
asS'test_loss'
p3
(lp4
F4.524246826171875
aF4.395648498535156
aF4.281025085449219
aF4.149393615722656
aF4.023324584960937
aF3.926106262207031
aF3.8047500610351563
aF3.713578186035156
aF3.602353515625
aF3.5122030639648436
aF3.420285949707031
aF3.345716857910156
aF3.276295166015625
aF3.235286865234375
aF3.14148681640625
aF3.075697326660156
aF3.024369812011719
aF2.9665863037109377
aF2.9297027587890625
aF2.935189208984375
aF2.8694720458984375
aF2.822585144042969
aF2.798794860839844
aF2.794334716796875
aF2.751615295410156
aF2.726756286621094
aF2.727967529296875
aF2.7164947509765627
aF2.7099188232421874
aF2.686418151855469
aF2.6715655517578125
aF2.670760498046875
aF2.6790036010742186
aF2.6537249755859373
aF2.645416259765625
aF2.6360299682617185
aF2.64376953125
aF2.6170916748046875
aF2.622215576171875
aF2.6114105224609374
aF2.605393981933594
aF2.5982012939453125
aF2.5863833618164063
aF2.5995526123046875
aF2.583904113769531
aF2.5848513793945314
aF2.5805624389648436
aF2.5532647705078126
aF2.5634185791015627
aF2.547465972900391
aF2.561492614746094
aF2.572279968261719
aF2.5622247314453124
aF2.55033447265625
aF2.557252960205078
aF2.562244567871094
aF2.5452726745605467
aF2.5258889770507813
aF2.5381228637695314
aF2.522535705566406
aF2.514359130859375
aF2.534099426269531
aF2.5453427124023436
aF2.5173419189453123
aF2.532614898681641
aF2.5204403686523436
aF2.517646484375
aF2.512770538330078
aF2.501311950683594
aF2.506029052734375
aF2.5054380798339846
aF2.5145257568359374
aF2.5208277893066406
aF2.5168951416015624
aF2.5069515991210936
aF2.502982330322266
aF2.5026324462890623
aF2.511923980712891
aF2.495545654296875
aF2.503220672607422
aF2.5003230285644533
aF2.493440704345703
aF2.4919911193847657
aF2.4833160400390626
aF2.4871900939941405
aF2.5010699462890624
aF2.489041748046875
aF2.493325500488281
aF2.491312255859375
aF2.498548736572266
aF2.4955683898925782
aF2.4825430297851563
aF2.495508270263672
aF2.4932135009765624
aF2.4873614501953125
aF2.472207489013672
aF2.48314453125
aF2.479278564453125
aF2.472608642578125
aF2.4872283935546875
asS'chunk_len'
p5
I200
sS'learning_rate'
p6
F0.0009528697504895834
sS'batch_size'
p7
I100
sS'n_epochs'
p8
I100
sS'elapsed_time'
p9
S'1m 10s'
p10
sS'final_test_loss'
p11
F2.4872283935546875
sS'num_layers'
p12
cnumpy.core.multiarray
scalar
p13
(cnumpy
dtype
p14
(S'i8'
p15
I0
I1
tp16
Rp17
(I3
S'<'
p18
NNNI-1
I-1
I0
tp19
bS'\x01\x00\x00\x00\x00\x00\x00\x00'
p20
tp21
Rp22
sS'model'
p23
S'vanilla_tanh_diag'
p24
sS'hidden_size'
p25
g13
(g17
S'\xe7\x00\x00\x00\x00\x00\x00\x00'
p26
tp27
Rp28
s.