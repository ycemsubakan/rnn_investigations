(dp0
S'train_loss'
p1
(lp2
F4.615101013183594
aF4.60375244140625
aF4.590670471191406
aF4.581484375
aF4.568602294921875
aF4.557057189941406
aF4.5506765747070315
aF4.535845336914062
aF4.5275271606445315
aF4.51548828125
aF4.5055078125
aF4.49395263671875
aF4.484218444824219
aF4.469799499511719
aF4.459107360839844
aF4.4490509033203125
aF4.439358215332032
aF4.42751953125
aF4.412001342773437
aF4.409281921386719
aF4.392335205078125
aF4.381419372558594
aF4.378672790527344
aF4.356143493652343
aF4.34765869140625
aF4.333012390136719
aF4.329100341796875
aF4.3126373291015625
aF4.3027340698242185
aF4.288793029785157
aF4.2702178955078125
aF4.259120483398437
aF4.2562734985351565
aF4.230400390625
aF4.227197570800781
aF4.209100036621094
aF4.193013000488281
aF4.186723022460938
aF4.1656787109375
aF4.150747375488281
aF4.1394216918945315
aF4.124239807128906
aF4.105958862304687
aF4.090066528320312
aF4.074533996582031
aF4.065609130859375
aF4.049469909667969
aF4.018227233886718
aF4.007673645019532
aF4.0036572265625
aF3.977139892578125
aF3.96808837890625
aF3.940927734375
aF3.9311407470703124
aF3.9077886962890624
aF3.887948303222656
aF3.872357177734375
aF3.8499795532226564
aF3.8249691772460936
aF3.823922119140625
aF3.8062103271484373
aF3.7645965576171876
aF3.75114990234375
aF3.7443478393554686
aF3.7368588256835937
aF3.709530944824219
aF3.672054443359375
aF3.6661691284179687
aF3.643046875
aF3.627174987792969
aF3.6095852661132812
aF3.5940557861328126
aF3.5683218383789064
aF3.5465875244140626
aF3.5544610595703126
aF3.5210885620117187
aF3.5045700073242188
aF3.47773681640625
aF3.4688653564453125
aF3.4244985961914063
aF3.418924560546875
aF3.4067779541015626
aF3.3760552978515626
aF3.3722027587890624
aF3.3584002685546874
aF3.359081115722656
aF3.323150634765625
aF3.3166207885742187
aF3.28704833984375
aF3.2952166748046876
aF3.25268310546875
aF3.2678536987304687
aF3.247378234863281
aF3.232962951660156
aF3.2218524169921876
aF3.2208154296875
aF3.1776531982421874
aF3.182913818359375
aF3.1629769897460935
aF3.15934814453125
asS'test_loss'
p3
(lp4
F4.602917785644531
aF4.591846923828125
aF4.583032531738281
aF4.569200134277343
aF4.559299011230468
aF4.550210876464844
aF4.5358734130859375
aF4.526802978515625
aF4.5166104125976565
aF4.504996337890625
aF4.493246459960938
aF4.481852722167969
aF4.470953063964844
aF4.457417907714844
aF4.450481567382813
aF4.440775451660156
aF4.425843505859375
aF4.414421081542969
aF4.405769653320313
aF4.396434020996094
aF4.384608154296875
aF4.367182006835938
aF4.360995178222656
aF4.349835510253906
aF4.329110717773437
aF4.320747375488281
aF4.309788208007813
aF4.300054931640625
aF4.280850830078125
aF4.271175537109375
aF4.2602017211914065
aF4.249306335449218
aF4.230315551757813
aF4.220505981445313
aF4.195724182128906
aF4.196836853027344
aF4.177401733398438
aF4.164676513671875
aF4.149151000976563
aF4.139130249023437
aF4.106827087402344
aF4.10843017578125
aF4.091136779785156
aF4.07181640625
aF4.060656127929687
aF4.038026428222656
aF4.0340509033203125
aF4.00762939453125
aF4.000198059082031
aF3.9781930541992185
aF3.9593817138671876
aF3.949909362792969
aF3.9199948120117187
aF3.9024609375
aF3.8996600341796874
aF3.8873977661132812
aF3.8435809326171877
aF3.839228210449219
aF3.8027166748046874
aF3.7819354248046877
aF3.7780889892578124
aF3.7535995483398437
aF3.740791015625
aF3.7139492797851563
aF3.6952590942382812
aF3.6757183837890626
aF3.6653656005859374
aF3.648250732421875
aF3.6239413452148437
aF3.609075927734375
aF3.5689599609375
aF3.5688217163085936
aF3.532305908203125
aF3.529371337890625
aF3.5186508178710936
aF3.5039218139648436
aF3.466643981933594
aF3.4783050537109377
aF3.430613708496094
aF3.4090951538085936
aF3.4155087280273437
aF3.400837707519531
aF3.3673663330078125
aF3.3585745239257814
aF3.3420956420898436
aF3.312218017578125
aF3.329691162109375
aF3.3030035400390627
aF3.28673828125
aF3.295768127441406
aF3.264454650878906
aF3.2289578247070314
aF3.2238720703125
aF3.210210266113281
aF3.209189453125
aF3.193959045410156
aF3.205667724609375
aF3.1872747802734374
aF3.147657775878906
aF3.1434231567382813
asS'chunk_len'
p5
I200
sS'learning_rate'
p6
F0.0001245118665173874
sS'batch_size'
p7
I100
sS'n_epochs'
p8
I100
sS'elapsed_time'
p9
S'1m 33s'
p10
sS'final_test_loss'
p11
F3.1434231567382813
sS'num_layers'
p12
cnumpy.core.multiarray
scalar
p13
(cnumpy
dtype
p14
(S'i8'
p15
I0
I1
tp16
Rp17
(I3
S'<'
p18
NNNI-1
I-1
I0
tp19
bS'\x02\x00\x00\x00\x00\x00\x00\x00'
p20
tp21
Rp22
sS'model'
p23
S'vanilla_tanh_diag'
p24
sS'hidden_size'
p25
g13
(g17
S'\xa9\x00\x00\x00\x00\x00\x00\x00'
p26
tp27
Rp28
s.