(dp0
S'train_loss'
p1
(lp2
F4.61258544921875
aF4.545628051757813
aF4.473466796875
aF4.405455627441406
aF4.341578979492187
aF4.2729055786132815
aF4.205545959472656
aF4.14055419921875
aF4.08689208984375
aF4.010147399902344
aF3.96115478515625
aF3.8875662231445314
aF3.829697265625
aF3.769207763671875
aF3.710560302734375
aF3.6657400512695313
aF3.6006085205078127
aF3.5304339599609373
aF3.50620361328125
aF3.461425476074219
aF3.378775329589844
aF3.3622369384765625
aF3.320338134765625
aF3.2502996826171877
aF3.2233734130859375
aF3.193722839355469
aF3.1266909790039064
aF3.1147079467773438
aF3.1054531860351564
aF3.045391845703125
aF3.019736022949219
aF2.9766656494140626
aF2.96617431640625
aF2.9502813720703127
aF2.925982666015625
aF2.892084045410156
aF2.8817852783203124
aF2.851898193359375
aF2.8314175415039062
aF2.813262939453125
aF2.8503106689453124
aF2.808527526855469
aF2.7897305297851562
aF2.76427490234375
aF2.733736877441406
aF2.779668273925781
aF2.7537786865234377
aF2.731475830078125
aF2.742151184082031
aF2.723474426269531
aF2.711240539550781
aF2.7266815185546873
aF2.707296142578125
aF2.690749206542969
aF2.6923477172851564
aF2.706409606933594
aF2.7091033935546873
aF2.680823974609375
aF2.670267333984375
aF2.6455413818359377
aF2.6577496337890625
aF2.6633987426757812
aF2.664043273925781
aF2.64258056640625
aF2.622644958496094
aF2.6429714965820312
aF2.6510464477539064
aF2.6271377563476563
aF2.6348190307617188
aF2.62804931640625
aF2.61942626953125
aF2.6195306396484375
aF2.619393005371094
aF2.6219580078125
aF2.5949575805664065
aF2.607574768066406
aF2.5969363403320314
aF2.591377868652344
aF2.604439392089844
aF2.575936584472656
aF2.6024209594726564
aF2.5987451171875
aF2.58526611328125
aF2.603094482421875
aF2.585806884765625
aF2.56662109375
aF2.5880300903320315
aF2.5989947509765625
aF2.589283752441406
aF2.5679400634765623
aF2.569246826171875
aF2.5686279296875
aF2.5619686889648436
aF2.566344909667969
aF2.5622882080078124
aF2.547606964111328
aF2.5666213989257813
aF2.5499504089355467
aF2.5468876647949217
aF2.55147216796875
asS'test_loss'
p3
(lp4
F4.543594970703125
aF4.474888000488281
aF4.405122985839844
aF4.336332702636719
aF4.272811279296875
aF4.205489807128906
aF4.134512329101563
aF4.073888854980469
aF4.012365417480469
aF3.9538690185546876
aF3.8829852294921876
aF3.822511901855469
aF3.7639285278320314
aF3.7162319946289064
aF3.666021728515625
aF3.5856594848632812
aF3.555281066894531
aF3.5020040893554687
aF3.437867431640625
aF3.383256530761719
aF3.3455569458007814
aF3.2938223266601563
aF3.2430709838867187
aF3.200067443847656
aF3.163926696777344
aF3.13414794921875
aF3.0947235107421873
aF3.0858309936523436
aF3.032509765625
aF3.0314370727539064
aF2.9696112060546875
aF2.9514813232421875
aF2.9263787841796876
aF2.9491061401367187
aF2.8810025024414063
aF2.8877264404296876
aF2.842062683105469
aF2.8522528076171874
aF2.841597900390625
aF2.8119671630859373
aF2.803846740722656
aF2.7993621826171875
aF2.7754632568359376
aF2.7412835693359376
aF2.741448974609375
aF2.7463824462890627
aF2.733343200683594
aF2.7138906860351564
aF2.737141418457031
aF2.696729736328125
aF2.697723083496094
aF2.703446044921875
aF2.69718017578125
aF2.673314514160156
aF2.6835986328125
aF2.683954162597656
aF2.668543395996094
aF2.663856201171875
aF2.6589178466796874
aF2.6391946411132814
aF2.657840576171875
aF2.6419107055664064
aF2.6466268920898437
aF2.626541748046875
aF2.6236306762695314
aF2.6358468627929685
aF2.621360168457031
aF2.630306396484375
aF2.6161093139648437
aF2.6097216796875
aF2.6247512817382814
aF2.6124777221679687
aF2.6167730712890624
aF2.5943829345703127
aF2.6054571533203124
aF2.582562255859375
aF2.5995303344726564
aF2.599775695800781
aF2.5928997802734375
aF2.568703918457031
aF2.5686776733398435
aF2.58281005859375
aF2.575711364746094
aF2.5775555419921874
aF2.5638916015625
aF2.590059814453125
aF2.5646896362304688
aF2.5732421875
aF2.547715759277344
aF2.5691400146484376
aF2.5664764404296876
aF2.536300048828125
aF2.5490956115722656
aF2.536387939453125
aF2.5450184631347654
aF2.5508573913574217
aF2.5718399047851563
aF2.5407728576660156
aF2.5260049438476564
aF2.528489227294922
asS'chunk_len'
p5
I200
sS'learning_rate'
p6
F0.0004973895357238025
sS'batch_size'
p7
I100
sS'n_epochs'
p8
I100
sS'elapsed_time'
p9
S'1m 11s'
p10
sS'final_test_loss'
p11
F2.528489227294922
sS'num_layers'
p12
cnumpy.core.multiarray
scalar
p13
(cnumpy
dtype
p14
(S'i8'
p15
I0
I1
tp16
Rp17
(I3
S'<'
p18
NNNI-1
I-1
I0
tp19
bS'\x01\x00\x00\x00\x00\x00\x00\x00'
p20
tp21
Rp22
sS'model'
p23
S'vanilla_tanh_diag'
p24
sS'hidden_size'
p25
g13
(g17
S'\xf0\x00\x00\x00\x00\x00\x00\x00'
p26
tp27
Rp28
s.