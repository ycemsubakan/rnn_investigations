(dp0
S'train_loss'
p1
(lp2
F4.644442138671875
aF4.590982666015625
aF4.538936767578125
aF4.480112915039062
aF4.429273071289063
aF4.379622497558594
aF4.320384521484375
aF4.2744140625
aF4.22110107421875
aF4.175872802734375
aF4.127962951660156
aF4.076852722167969
aF4.0295361328125
aF3.983195495605469
aF3.935530700683594
aF3.89029296875
aF3.834284362792969
aF3.8002960205078127
aF3.7494775390625
aF3.6909530639648436
aF3.644998779296875
aF3.598126220703125
aF3.577120666503906
aF3.5228726196289064
aF3.4846505737304687
aF3.4088092041015625
aF3.4066232299804686
aF3.364122009277344
aF3.33489990234375
aF3.287722473144531
aF3.2479238891601563
aF3.2030389404296873
aF3.1801513671875
aF3.15213134765625
aF3.143568420410156
aF3.0977862548828123
aF3.0910745239257813
aF3.062158508300781
aF3.0271926879882813
aF3.0333746337890624
aF2.9898300170898438
aF2.9740176391601563
aF2.951761474609375
aF2.9700592041015623
aF2.9255877685546876
aF2.907934265136719
aF2.9009719848632813
aF2.9029977416992185
aF2.8782363891601563
aF2.840246276855469
aF2.849554138183594
aF2.816652526855469
aF2.8367684936523436
aF2.8063455200195313
aF2.810178527832031
aF2.794337158203125
aF2.7970895385742187
aF2.7794073486328124
aF2.7509390258789064
aF2.745879821777344
aF2.7351528930664064
aF2.7342349243164064
aF2.73073486328125
aF2.7474246215820313
aF2.7147418212890626
aF2.716996154785156
aF2.72867431640625
aF2.71673828125
aF2.717204284667969
aF2.7058905029296874
aF2.6820550537109376
aF2.68255859375
aF2.6845721435546874
aF2.665673828125
aF2.68181396484375
aF2.695790100097656
aF2.6636102294921873
aF2.645091552734375
aF2.662597351074219
aF2.6542318725585936
aF2.6739984130859376
aF2.653464660644531
aF2.648318176269531
aF2.638799743652344
aF2.6265658569335937
aF2.633120422363281
aF2.633495178222656
aF2.6145700073242186
aF2.6531890869140624
aF2.6190972900390626
aF2.6257168579101564
aF2.6284771728515626
aF2.6159292602539064
aF2.6265829467773436
aF2.6210678100585936
aF2.6108184814453126
aF2.614613342285156
aF2.6095843505859375
aF2.5970477294921874
aF2.6256787109375
asS'test_loss'
p3
(lp4
F4.593340759277344
aF4.533377685546875
aF4.481794738769532
aF4.432485961914063
aF4.382388916015625
aF4.319341430664062
aF4.276659545898437
aF4.2236395263671875
aF4.181468200683594
aF4.1306765747070315
aF4.077242431640625
aF4.040523071289062
aF3.961314697265625
aF3.9216949462890627
aF3.879972229003906
aF3.832657470703125
aF3.77445068359375
aF3.7293240356445314
aF3.6923052978515627
aF3.658760681152344
aF3.6236810302734375
aF3.5615664672851564
aF3.5114495849609373
aF3.4869580078125
aF3.4369100952148437
aF3.395643615722656
aF3.373451843261719
aF3.319661865234375
aF3.2566510009765626
aF3.2425527954101563
aF3.2353558349609375
aF3.1869430541992188
aF3.1372418212890625
aF3.1240383911132814
aF3.113717346191406
aF3.0745709228515623
aF3.0418231201171877
aF3.0366650390625
aF3.0190005493164063
aF2.9917327880859377
aF2.96703125
aF2.9289785766601564
aF2.932453308105469
aF2.9274407958984376
aF2.9128384399414062
aF2.8865283203125
aF2.864849853515625
aF2.871500244140625
aF2.837041931152344
aF2.82118896484375
aF2.8314044189453127
aF2.8171026611328127
aF2.8023715209960938
aF2.776426086425781
aF2.7918240356445314
aF2.778214111328125
aF2.760760498046875
aF2.769106140136719
aF2.7639840698242186
aF2.7360662841796874
aF2.7356631469726564
aF2.7092025756835936
aF2.7201116943359374
aF2.7321429443359375
aF2.7212811279296876
aF2.6978759765625
aF2.708677062988281
aF2.676405334472656
aF2.6869268798828125
aF2.701291198730469
aF2.6742343139648437
aF2.664027099609375
aF2.693412170410156
aF2.688321838378906
aF2.6505267333984377
aF2.6699905395507812
aF2.6661407470703127
aF2.673240051269531
aF2.63220947265625
aF2.6499899291992186
aF2.641742858886719
aF2.6521575927734373
aF2.6399465942382814
aF2.618100280761719
aF2.6458282470703125
aF2.624831237792969
aF2.6188934326171873
aF2.6253781127929687
aF2.6046258544921876
aF2.6154376220703126
aF2.6187744140625
aF2.6152880859375
aF2.611319885253906
aF2.614255676269531
aF2.6163873291015625
aF2.59078125
aF2.6119729614257814
aF2.5972390747070313
aF2.6004705810546875
aF2.5992813110351562
asS'chunk_len'
p5
I200
sS'learning_rate'
p6
F0.0005538413811399911
sS'batch_size'
p7
I100
sS'n_epochs'
p8
I100
sS'elapsed_time'
p9
S'1m 1s'
p10
sS'final_test_loss'
p11
F2.5992813110351562
sS'num_layers'
p12
cnumpy.core.multiarray
scalar
p13
(cnumpy
dtype
p14
(S'i8'
p15
I0
I1
tp16
Rp17
(I3
S'<'
p18
NNNI-1
I-1
I0
tp19
bS'\x01\x00\x00\x00\x00\x00\x00\x00'
p20
tp21
Rp22
sS'model'
p23
S'vanilla_tanh_diag'
p24
sS'hidden_size'
p25
g13
(g17
S'\xaf\x00\x00\x00\x00\x00\x00\x00'
p26
tp27
Rp28
s.