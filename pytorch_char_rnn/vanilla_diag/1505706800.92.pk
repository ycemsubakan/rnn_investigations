(dp0
S'train_loss'
p1
(lp2
F4.668333740234375
aF4.65798095703125
aF4.645444030761719
aF4.635744323730469
aF4.624220581054687
aF4.6142236328125
aF4.6032171630859375
aF4.589103088378907
aF4.581568298339843
aF4.567119140625
aF4.5540463256835935
aF4.5440234375
aF4.53228271484375
aF4.522892456054688
aF4.50775146484375
aF4.500581359863281
aF4.489927673339844
aF4.475548095703125
aF4.46133056640625
aF4.449555969238281
aF4.441629333496094
aF4.429370727539062
aF4.420493469238282
aF4.408706970214844
aF4.395845031738281
aF4.3837158203125
aF4.367246398925781
aF4.360957336425781
aF4.3455133056640625
aF4.340906677246093
aF4.3238067626953125
aF4.3085940551757815
aF4.306110534667969
aF4.291825561523438
aF4.282013854980469
aF4.262140197753906
aF4.2596432495117185
aF4.241305541992188
aF4.229546203613281
aF4.213893432617187
aF4.199268493652344
aF4.187840270996094
aF4.175777282714844
aF4.157698669433594
aF4.150043640136719
aF4.131860046386719
aF4.127491149902344
aF4.108291320800781
aF4.098226013183594
aF4.089832458496094
aF4.063283081054688
aF4.066001586914062
aF4.041265869140625
aF4.020875854492187
aF4.0164727783203125
aF4.010332641601562
aF3.9897052001953126
aF3.9804022216796877
aF3.959625244140625
aF3.9502139282226563
aF3.936293029785156
aF3.920365295410156
aF3.9086212158203124
aF3.894386901855469
aF3.8777346801757813
aF3.8674462890625
aF3.8506939697265623
aF3.8336227416992186
aF3.823519287109375
aF3.8079449462890627
aF3.8068087768554686
aF3.77684814453125
aF3.7615789794921874
aF3.75904541015625
aF3.741988220214844
aF3.731893310546875
aF3.700994873046875
aF3.6977288818359373
aF3.6844021606445314
aF3.673742370605469
aF3.6600192260742186
aF3.639723205566406
aF3.6308782958984374
aF3.6240692138671875
aF3.6113067626953126
aF3.586211853027344
aF3.5757406616210936
aF3.5800830078125
aF3.554046630859375
aF3.534512634277344
aF3.5284823608398437
aF3.52637451171875
aF3.5287820434570314
aF3.4829315185546874
aF3.4872006225585936
aF3.464180908203125
aF3.449510498046875
aF3.4509747314453123
aF3.4285516357421875
aF3.4241458129882814
asS'test_loss'
p3
(lp4
F4.660135192871094
aF4.649237365722656
aF4.635196838378906
aF4.623140563964844
aF4.611912231445313
aF4.600078430175781
aF4.5869448852539065
aF4.577775268554688
aF4.5678927612304685
aF4.554294738769531
aF4.543390502929688
aF4.531449279785156
aF4.520066833496093
aF4.511125183105468
aF4.497842407226562
aF4.489977416992187
aF4.4747012329101565
aF4.46097412109375
aF4.4527499389648435
aF4.440294189453125
aF4.428931884765625
aF4.422181091308594
aF4.408838806152343
aF4.39503173828125
aF4.3823785400390625
aF4.371512756347657
aF4.3654296875
aF4.347864990234375
aF4.3325936889648435
aF4.326153259277344
aF4.310692443847656
aF4.3023486328125
aF4.283968200683594
aF4.270204467773437
aF4.260050659179687
aF4.2488470458984375
aF4.230589904785156
aF4.221952514648438
aF4.207102661132812
aF4.197462463378907
aF4.185020751953125
aF4.166763916015625
aF4.158182678222656
aF4.152499084472656
aF4.138576965332032
aF4.126835021972656
aF4.101383361816406
aF4.109989013671875
aF4.0778805541992185
aF4.0678622436523435
aF4.0561001586914065
aF4.042126159667969
aF4.028360900878906
aF4.01469970703125
aF4.0015631103515625
aF3.9879495239257814
aF3.973780212402344
aF3.9629913330078126
aF3.9517330932617187
aF3.93983642578125
aF3.905028991699219
aF3.909638671875
aF3.8966632080078125
aF3.880467529296875
aF3.862853698730469
aF3.8435372924804687
aF3.8355841064453124
aF3.826187744140625
aF3.8039810180664064
aF3.7948974609375
aF3.778037109375
aF3.7564260864257815
aF3.7408157348632813
aF3.7329241943359377
aF3.719909973144531
aF3.693913879394531
aF3.686138000488281
aF3.6796722412109375
aF3.6608447265625
aF3.6440414428710937
aF3.6341876220703124
aF3.6213088989257813
aF3.624173278808594
aF3.609369812011719
aF3.579727783203125
aF3.5834637451171876
aF3.569593811035156
aF3.555406494140625
aF3.5447601318359374
aF3.533509521484375
aF3.5119613647460937
aF3.494812316894531
aF3.4863214111328125
aF3.4944659423828126
aF3.45489501953125
aF3.4548635864257813
aF3.4495840454101563
aF3.441639099121094
aF3.4064569091796875
aF3.3902627563476564
asS'chunk_len'
p5
I200
sS'learning_rate'
p6
F0.00022060703296271258
sS'batch_size'
p7
I100
sS'n_epochs'
p8
I100
sS'elapsed_time'
p9
S'0m 49s'
p10
sS'final_test_loss'
p11
F3.3902627563476564
sS'num_layers'
p12
cnumpy.core.multiarray
scalar
p13
(cnumpy
dtype
p14
(S'i8'
p15
I0
I1
tp16
Rp17
(I3
S'<'
p18
NNNI-1
I-1
I0
tp19
bS'\x01\x00\x00\x00\x00\x00\x00\x00'
p20
tp21
Rp22
sS'model'
p23
S'vanilla_tanh_diag'
p24
sS'hidden_size'
p25
g13
(g17
S'g\x00\x00\x00\x00\x00\x00\x00'
p26
tp27
Rp28
s.